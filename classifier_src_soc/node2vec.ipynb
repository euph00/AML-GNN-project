{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b190d5",
   "metadata": {},
   "source": [
    "# USE NODE2VEC/DEEPWALK TO GENERATE ACCOUNT EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b260530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "from modules.data_loader import *\n",
    "from modules.feature_engineering import *\n",
    "from modules.visualizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2913730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #run if you dont have the data downloaded this is a few gb of data\n",
    "# import kagglehub\n",
    "# path = kagglehub.dataset_download(\"ealtman2019/ibm-transactions-for-anti-money-laundering-aml\")\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3353db",
   "metadata": {},
   "source": [
    "## 1. Create our dataframes from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd4923a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HI-Small...\n",
      "\n",
      "\n",
      "Loading transactions from: /home/linch/.cache/kagglehub/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml/versions/8/HI-Small_Trans.csv\n",
      "File size: 453.6 MB\n",
      "\n",
      "Loaded 5,078,345 transactions\n",
      "Date range: 2022-09-01 00:00:00 to 2022-09-18 16:18:00\n",
      "Laundering transactions: 5,177 (0.102%)\n",
      "\n",
      "Loading accounts from: /home/linch/.cache/kagglehub/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml/versions/8/HI-Small_accounts.csv\n",
      "\n",
      "Loaded 518,581 accounts from 30470 banks\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"HI-Small\"\n",
    "\n",
    "print(f\"Loading {dataset_name}...\\n\")\n",
    "trans_df = load_transactions(dataset_size=dataset_name)\n",
    "accounts_df = load_accounts(dataset_size=dataset_name)\n",
    "# patterns_df = load_patterns(dataset_size=dataset_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b5755",
   "metadata": {},
   "source": [
    "## 2. Feature engineering - For this notebook, we calculate several different statistics to do manual feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db4666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all currencies to USD for normaliztion\n",
    "\n",
    "trans_df = convert_currency_to_USD(trans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "725f3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successfully verified that currency conversion is within margin of error\n",
    "\n",
    "# trans_df_verification = trans_df.copy()\n",
    "# trans_df_verification[\"diff\"] = trans_df[\"amount_received\"] - trans_df[\"amount_paid\"]\n",
    "# show = [\"amount_received\", \"receiving_currency\", \"amount_paid\", \"payment_currency\", \"diff\"]\n",
    "# print(trans_df_verification.loc[trans_df_verification['diff'] > 50, show])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "361bf703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "-1.0\n",
      "1.0\n",
      "-1.0\n",
      "4.282624796869565\n",
      "-1.3776303742917988\n",
      "1.2980283339374991e-13\n"
     ]
    }
   ],
   "source": [
    "# compute sinusoidal temporal encodings and normalized unix timestamp\n",
    "\n",
    "trans_df = temporal_encoding(trans_df)\n",
    "print(trans_df['hour_sin'].max())\n",
    "print(trans_df['hour_sin'].min())\n",
    "print(trans_df['hour_cos'].max())\n",
    "print(trans_df['hour_cos'].min())\n",
    "print(trans_df['time_normalized'].max())\n",
    "print(trans_df['time_normalized'].min())\n",
    "print(trans_df['time_normalized'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17bb56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          12\n",
      "1          12\n",
      "2          12\n",
      "3          12\n",
      "4          12\n",
      "           ..\n",
      "5078340     1\n",
      "5078341     1\n",
      "5078342     1\n",
      "5078343     1\n",
      "5078344     1\n",
      "Name: receiving_currency_id, Length: 5078345, dtype: category\n",
      "Categories (15, int64): [0, 1, 3, 4, ..., 2, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# give each currency and payment method a unique integer ID\n",
    "\n",
    "trans_df = encode_currency_ids(trans_df)\n",
    "trans_df = encode_payment_format_ids(trans_df)\n",
    "print(trans_df['receiving_currency_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ecd14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515079\n",
      "518581\n",
      "518573\n"
     ]
    }
   ],
   "source": [
    "# give each account a unique integer ID\n",
    "\n",
    "trans_df, account_to_id, id_to_account = encode_account_ids(trans_df)\n",
    "print(max(trans_df['to_account_id'].max(), trans_df['from_account_id'].max()))\n",
    "print(len(accounts_df))\n",
    "print(len(accounts_df['account_id'].unique()))\n",
    "\n",
    "# When working with transactions df, we see that only 515079 + 1 = 515080 accounts appear. This means only 515800 accounts have transacted. We will ignore accounts with no transactions.\n",
    "# There are 518581 rows in the accounts df, we see there are 518581 rows. However there are only 518573 unique account numbers, which corroborates with the datacard on kaggle. This is likely because there are a few accounts that have different values for bank but share the same account id. We will treat them as the same account for now as we are ignoring the bank data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6kt67xtz4c9",
   "metadata": {},
   "source": [
    "## 3. Temporal train/test split and account statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0nzrvv4m8bqr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEMPORAL TRAIN/TEST SPLIT\n",
      "============================================================\n",
      "\n",
      "Train Set:\n",
      "  Date range: 2022-09-01 00:00:00 to 2022-09-08 16:12:00\n",
      "  Transactions: 4,062,676\n",
      "  Laundering: 3,380 (0.083%)\n",
      "\n",
      "Test Set:\n",
      "  Date range: 2022-09-08 16:12:00 to 2022-09-18 16:18:00\n",
      "  Transactions: 1,015,669\n",
      "  Laundering: 1,797 (0.177%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# split data temporally: first 80% for training, last 20% for testing\n",
    "\n",
    "train_df, test_df = temporal_train_test_split(trans_df, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ocw8qw7vyh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set amount normalization:\n",
      "  amount_paid - Mean: 8.88e-16, Std: 1.0000\n",
      "  amount_received - Mean: -6.99e-16, Std: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Normalize amounts (log transform, zero center, scale) for training set\n",
    "\n",
    "train_df = normalize_amounts(train_df)\n",
    "print(\"Train set amount normalization:\")\n",
    "print(f\"  amount_paid - Mean: {train_df['amount_paid'].mean():.2e}, Std: {train_df['amount_paid'].std():.4f}\")\n",
    "print(f\"  amount_received - Mean: {train_df['amount_received'].mean():.2e}, Std: {train_df['amount_received'].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2wybs7vif1s",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set amount normalization:\n",
      "  amount_paid - Mean: -3.86e-16, Std: 1.0000\n",
      "  amount_received - Mean: 7.16e-16, Std: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Normalize amounts for test set\n",
    "\n",
    "test_df = normalize_amounts(test_df)\n",
    "print(\"Test set amount normalization:\")\n",
    "print(f\"  amount_paid - Mean: {test_df['amount_paid'].mean():.2e}, Std: {test_df['amount_paid'].std():.4f}\")\n",
    "print(f\"  amount_received - Mean: {test_df['amount_received'].mean():.2e}, Std: {test_df['amount_received'].std():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
