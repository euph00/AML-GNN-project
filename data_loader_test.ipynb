{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cbe6d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abc72823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import dgl\n",
    "# import dgl.graphbolt as gb\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "# from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from eda_src.data_loader import load_transactions, load_accounts, load_patterns\n",
    "from eda_src.feature_engineering import apply_feature_eng_accounts, apply_feature_eng_transactions\n",
    "from models import AMLModelTrainer, GraphAttentionNetwork\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2364f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HI-Small...\n",
      "\n",
      "\n",
      "Loading transactions from: /home/bernard/.cache/kagglehub/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml/versions/8/HI-Small_Trans.csv\n",
      "File size: 453.6 MB\n",
      "\n",
      "Loaded 5,078,345 transactions\n",
      "Date range: 2022-09-01 00:00:00 to 2022-09-18 16:18:00\n",
      "Laundering transactions: 5,177 (0.102%)\n",
      "\n",
      "Loading accounts from: /home/bernard/.cache/kagglehub/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml/versions/8/HI-Small_accounts.csv\n",
      "\n",
      "Loaded 518,581 accounts from 30470 banks\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_bank_account_id</th>\n",
       "      <th>to_bank_account_id</th>\n",
       "      <th>log_amount_paid</th>\n",
       "      <th>log_amount_received</th>\n",
       "      <th>amount_ratio</th>\n",
       "      <th>amount_diff</th>\n",
       "      <th>currency_match</th>\n",
       "      <th>same_bank</th>\n",
       "      <th>is_laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_8000EBD30</td>\n",
       "      <td>10_8000EBD30</td>\n",
       "      <td>3.567889</td>\n",
       "      <td>3.567889</td>\n",
       "      <td>-0.005122</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  from_bank_account_id to_bank_account_id  log_amount_paid  \\\n",
       "0         10_8000EBD30       10_8000EBD30         3.567889   \n",
       "\n",
       "   log_amount_received  amount_ratio  amount_diff  currency_match  same_bank  \\\n",
       "0             3.567889     -0.005122     0.002653               1          1   \n",
       "\n",
       "   is_laundering  \n",
       "0              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank_account_id</th>\n",
       "      <th>entity_type_Corporation</th>\n",
       "      <th>entity_type_Country</th>\n",
       "      <th>entity_type_Direct</th>\n",
       "      <th>entity_type_Individual</th>\n",
       "      <th>entity_type_Partnership</th>\n",
       "      <th>entity_type_Sole Proprietorship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>331579_80B779D80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bank_account_id  entity_type_Corporation  entity_type_Country  \\\n",
       "0  331579_80B779D80                        0                    0   \n",
       "\n",
       "   entity_type_Direct  entity_type_Individual  entity_type_Partnership  \\\n",
       "0                   0                       0                        0   \n",
       "\n",
       "   entity_type_Sole Proprietorship  \n",
       "0                                1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = \"HI-Small\"\n",
    "\n",
    "print(f\"Loading {dataset_name}...\\n\")\n",
    "transactions_df = apply_feature_eng_transactions(load_transactions(dataset_size=dataset_name))\n",
    "accounts_df = apply_feature_eng_accounts(load_accounts(dataset_size=dataset_name))\n",
    "# patterns_df = load_patterns(dataset_size=dataset_name)\n",
    "\n",
    "display(transactions_df.head(1))\n",
    "display(accounts_df.head(1))\n",
    "# display(patterns_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd44f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMLGraphLoader:\n",
    "    \"\"\"\n",
    "    Handles loading data, building the DGL graph, and creating data loaders.\n",
    "    \n",
    "    The full graph 'g' is kept on the CPU. The EdgeDataLoader will sample\n",
    "    neighborhoods and create mini-batch 'blocks' that are moved to the GPU\n",
    "    during training, respecting the memory constraints.\n",
    "    \"\"\"\n",
    "    def __init__(self, accounts_df, transactions_df):\n",
    "        self.accounts_df = accounts_df\n",
    "        self.transactions_df = transactions_df\n",
    "        self.g = None\n",
    "        self._build_graph()\n",
    "        self.train_mask = None\n",
    "        self.val_mask = None\n",
    "        self.test_mask = None\n",
    "\n",
    "    def _build_graph(self):\n",
    "        print(\"Building graph...\")\n",
    "        \n",
    "        # 1. Map string account IDs to contiguous integer node IDs\n",
    "        # Using pd.Categorical is efficient for this\n",
    "        self.accounts_df['node_id'] = self.accounts_df['bank_account_id'].astype('category').cat.codes\n",
    "        account_id_map = self.accounts_df.set_index('bank_account_id')['node_id']\n",
    "        \n",
    "        self.transactions_df['src_nid'] = self.transactions_df['from_bank_account_id'].map(account_id_map)\n",
    "        self.transactions_df['dst_nid'] = self.transactions_df['to_bank_account_id'].map(account_id_map)\n",
    "\n",
    "        # Drop any transactions where mapping failed (e.g., account not in accounts_df)\n",
    "        self.transactions_df = self.transactions_df.dropna(subset=['src_nid', 'dst_nid'])\n",
    "        \n",
    "        # Get source and destination node IDs as tensors\n",
    "        src_nids = torch.tensor(self.transactions_df['src_nid'].values, dtype=torch.long)\n",
    "        dst_nids = torch.tensor(self.transactions_df['dst_nid'].values, dtype=torch.long)\n",
    "        \n",
    "        # 2. Create the DGL graph on the CPU\n",
    "        num_nodes = len(self.accounts_df)\n",
    "        self.g = dgl.graph((src_nids, dst_nids), num_nodes=num_nodes)\n",
    "        \n",
    "        # 3. Add node features\n",
    "        # Ensure features are sorted by the new 'node_id'\n",
    "        node_features_df = self.accounts_df.sort_values('node_id')\n",
    "        node_feats_tensor = torch.tensor(np.stack(node_features_df[\n",
    "            [\n",
    "                'entity_type_Corporation', \n",
    "                'entity_type_Country',\n",
    "                'entity_type_Direct', \n",
    "                'entity_type_Individual',\n",
    "                'entity_type_Partnership', \n",
    "                'entity_type_Sole Proprietorship'\n",
    "            ]].values), dtype=torch.float32)\n",
    "        self.g.ndata['feat'] = node_feats_tensor\n",
    "        \n",
    "        # 4. Add edge features and labels\n",
    "        # Tensors are created in the same order as the transactions_df, which matches edge order\n",
    "        edge_feats_tensor = torch.tensor(np.stack(self.transactions_df[\n",
    "            [\n",
    "                'log_amount_paid',\n",
    "                'log_amount_received', \n",
    "                'amount_ratio', \n",
    "                'amount_diff', \n",
    "                'currency_match',\n",
    "                'same_bank', \n",
    "                # 'payment_format_ACH',\n",
    "                # 'payment_format_Bitcoin', \n",
    "                # 'payment_format_Cash',\n",
    "                # 'payment_format_Cheque', \n",
    "                # 'payment_format_Credit Card',\n",
    "                # 'payment_format_Reinvestment', \n",
    "                # 'payment_format_Wire',\n",
    "                # 'receiving_currency_Australian Dollar', \n",
    "                # 'receiving_currency_Bitcoin',\n",
    "                # 'receiving_currency_Canadian Dollar',\n",
    "                # 'receiving_currency_Euro',\n",
    "                # 'receiving_currency_Mexican Peso',\n",
    "                # 'receiving_currency_Ruble',\n",
    "                # 'receiving_currency_Rupee',\n",
    "                # 'receiving_currency_UK Pound',\n",
    "                # 'receiving_currency_US Dollar',\n",
    "                # 'receiving_currency_Yen',\n",
    "                # 'receiving_currency_Yuan',\n",
    "                # 'receiving_currency_Brazil Real',\n",
    "                # 'receiving_currency_Saudi Riyal', \n",
    "                # 'receiving_currency_Shekel',\n",
    "                # 'receiving_currency_Swiss Franc', \n",
    "                # 'payment_currency_Australian Dollar',\n",
    "                # 'payment_currency_Bitcoin', \n",
    "                # 'payment_currency_Canadian Dollar',\n",
    "                # 'payment_currency_Euro', \n",
    "                # 'payment_currency_Mexican Peso',\n",
    "                # 'payment_currency_Ruble', \n",
    "                # 'payment_currency_Rupee',\n",
    "                # 'payment_currency_UK Pound', \n",
    "                # 'payment_currency_US Dollar',\n",
    "                # 'payment_currency_Yen', \n",
    "                # 'payment_currency_Yuan',\n",
    "                # 'payment_currency_Brazil Real', \n",
    "                # 'payment_currency_Saudi Riyal',\n",
    "                # 'payment_currency_Shekel', \n",
    "                # 'payment_currency_Swiss Franc'\n",
    "            ]].values), dtype=torch.float32)\n",
    "        edge_labels_tensor = torch.tensor(self.transactions_df['is_laundering'].values, dtype=torch.long)\n",
    "        \n",
    "        self.g.edata['feat'] = edge_feats_tensor\n",
    "        self.g.edata['label'] = edge_labels_tensor\n",
    "        \n",
    "        # 5. Create train/validation/test masks for edges\n",
    "        num_edges = self.g.num_edges()\n",
    "        eids = np.arange(num_edges)\n",
    "        \n",
    "        # Stratify split to ensure both classes are represented\n",
    "        try:\n",
    "            train_eids, test_eids, train_labels, test_labels = train_test_split(\n",
    "                eids, self.transactions_df['is_laundering'].values, test_size=0.3, random_state=42, stratify=self.transactions_df['is_laundering'].values\n",
    "            )\n",
    "            val_eids, test_eids, val_labels, test_labels = train_test_split(\n",
    "                test_eids, test_labels, test_size=0.5, random_state=42, stratify=test_labels\n",
    "            )\n",
    "        except ValueError:\n",
    "            # Fallback for small datasets where stratification fails\n",
    "            print(\"Warning: Stratification failed, using non-stratified split.\")\n",
    "            train_eids, test_eids = train_test_split(eids, test_size=0.3, random_state=42)\n",
    "            val_eids, test_eids = train_test_split(test_eids, test_size=0.5, random_state=42)\n",
    "            \n",
    "        train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "        \n",
    "        train_mask[train_eids] = True\n",
    "        val_mask[val_eids] = True\n",
    "        test_mask[test_eids] = True\n",
    "        \n",
    "        self.g.edata['train_mask'] = train_mask\n",
    "        self.g.edata['val_mask'] = val_mask\n",
    "        self.g.edata['test_mask'] = test_mask\n",
    "\n",
    "        print(\"Graph built successfully on CPU.\")\n",
    "        print(f\"  Nodes: {self.g.num_nodes()}\")\n",
    "        print(f\"  Edges: {self.g.num_edges()}\")\n",
    "        print(f\"  Train Edges: {train_mask.sum().item()}\")\n",
    "        print(f\"  Val Edges:   {val_mask.sum().item()}\")\n",
    "        print(f\"  Test Edges:  {test_mask.sum().item()}\")\n",
    "        \n",
    "    def get_dataloaders(self, batch_size, num_layers=2, fanouts=[15, 10]):\n",
    "        \"\"\"\n",
    "        Creates and returns the DGL EdgeDataLoaders for training, validation, and testing.\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int): Number of seed edges per mini-batch.\n",
    "            num_layers (int): Number of GNN layers.\n",
    "            fanouts (list): List of neighbor sampling sizes for each layer, from out-to-in.\n",
    "                            Must match num_layers.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (train_loader, val_loader, test_loader, full_graph)\n",
    "        \"\"\"\n",
    "        if len(fanouts) != num_layers:\n",
    "            raise ValueError(f\"Length of fanouts ({len(fanouts)}) must match num_layers ({num_layers}).\")\n",
    "            \n",
    "        # 1. Define the neighborhood sampler\n",
    "        # This samples neighborhoods for the src/dst nodes of the seed edges\n",
    "        sampler = dgl.dataloading.MultiLayerNeighborSampler(fanouts)\n",
    "\n",
    "        # 2. Get the Edge IDs for each set\n",
    "        # We use g.eids('all') to get the original edge IDs corresponding to the masks\n",
    "        train_eids = self.g.eids('all')[self.g.edata['train_mask']]\n",
    "        val_eids = self.g.eids('all')[self.g.edata['val_mask']]\n",
    "        test_eids = self.g.eids('all')[self.g.edata['test_mask']]\n",
    "\n",
    "        if mode == 'train':\n",
    "            mask = graph_data.train_mask\n",
    "        elif mode == 'val':\n",
    "            mask = graph_data.val_mask\n",
    "        else:\n",
    "            mask = graph_data.test_mask\n",
    "        \n",
    "        edge_ids = torch.where(mask)[0]\n",
    "        \n",
    "        # 3. Create the EdgeDataLoaders\n",
    "        # We set device='cpu' (default) and num_workers > 0\n",
    "        # The data loader will run sampling in parallel on CPU\n",
    "        # The main training loop will manually move blocks to the GPU\n",
    "        train_loader = dgl.dataloading.EdgeDataLoader(\n",
    "            self.g, train_eids, sampler,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "            num_workers=4  # Adjust based on your CPU cores\n",
    "        )\n",
    "        \n",
    "        val_loader = dgl.dataloading.EdgeDataLoader(\n",
    "            self.g, val_eids, sampler,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        test_loader = dgl.dataloading.EdgeDataLoader(\n",
    "            self.g, test_eids, sampler,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        print(\"DataLoaders created.\")\n",
    "        return train_loader, val_loader, test_loader, self.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e768a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building graph...\n",
      "Graph built successfully on CPU.\n",
      "  Nodes: 518581\n",
      "  Edges: 5078345\n",
      "  Train Edges: 3554841\n",
      "  Val Edges:   761752\n",
      "  Test Edges:  761752\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DGLGraph' object has no attribute 'eids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m loader_util \u001b[38;5;241m=\u001b[39m AMLGraphLoader(accounts_df, transactions_df)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 3. Get dataloaders\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m train_loader, val_loader, test_loader, full_graph \u001b[38;5;241m=\u001b[39m \u001b[43mloader_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloaders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfanouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 163\u001b[0m, in \u001b[0;36mAMLGraphLoader.get_dataloaders\u001b[0;34m(self, batch_size, num_layers, fanouts)\u001b[0m\n\u001b[1;32m    159\u001b[0m sampler \u001b[38;5;241m=\u001b[39m dgl\u001b[38;5;241m.\u001b[39mdataloading\u001b[38;5;241m.\u001b[39mMultiLayerNeighborSampler(fanouts)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# 2. Get the Edge IDs for each set\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# We use g.eids('all') to get the original edge IDs corresponding to the masks\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m train_eids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meids\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    164\u001b[0m val_eids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\u001b[38;5;241m.\u001b[39meids(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    165\u001b[0m test_eids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\u001b[38;5;241m.\u001b[39meids(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DGLGraph' object has no attribute 'eids'"
     ]
    }
   ],
   "source": [
    "# 2. Initialize the loader\n",
    "loader_util = AMLGraphLoader(accounts_df, transactions_df)\n",
    "\n",
    "# 3. Get dataloaders\n",
    "train_loader, val_loader, test_loader, full_graph = loader_util.get_dataloaders(\n",
    "    batch_size=1024, \n",
    "    num_layers=2, \n",
    "    fanouts=[15, 10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e6c709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b16487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa1ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43e521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0ba1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d5e056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22933725",
   "metadata": {},
   "source": [
    "### DGL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea6c0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GraphData:\n",
    "    \"\"\"Container for processed AML graph data ready for GNN training.\"\"\"\n",
    "    graph: dgl.DGLGraph\n",
    "    labels: torch.Tensor\n",
    "    train_mask: torch.Tensor\n",
    "    val_mask: torch.Tensor\n",
    "    test_mask: torch.Tensor\n",
    "    num_classes: int\n",
    "    node_features_dim: int\n",
    "    edge_features_dim: int\n",
    "    account_mapping: Dict[str, int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca3fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Data loader for Anti-Money Laundering graph construction with DGL.    \n",
    "    Supports GIN, PNA, and GAT models with temporal and edge features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        transactions_df: pd.DataFrame,\n",
    "        accounts_df: pd.DataFrame,\n",
    "        add_self_loops: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize AML data loader.\n",
    "        \n",
    "        Args:\n",
    "            transactions_df: Transaction data from load_transactions()\n",
    "            accounts_df: Account metadata from load_accounts()\n",
    "            add_self_loops: Whether to add self-loops to graph\n",
    "        \"\"\"\n",
    "        self.transactions = transactions_df.copy(deep=True)\n",
    "        self.accounts = accounts_df.copy(deep=True)\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        print(\"Initializing AML Data Loader...\")\n",
    "        print(f\"Transactions: {len(self.transactions):,}\")\n",
    "        print(f\"Accounts: {len(self.accounts):,}\")\n",
    "    \n",
    "    def _create_account_mapping(self) -> Dict[str, int]:\n",
    "        \"\"\"Create mapping from account IDs to node indices.\"\"\"\n",
    "        # Get unique accounts from both source and target\n",
    "        all_accounts = pd.concat([\n",
    "            self.transactions['from_bank_account_id'],\n",
    "            self.transactions['to_bank_account_id']\n",
    "        ]).unique()\n",
    "        \n",
    "        account_mapping = {acc: idx for idx, acc in enumerate(all_accounts)}\n",
    "        print(f\"Created account mapping: {len(account_mapping):,} unique accounts\")\n",
    "        return account_mapping\n",
    "    \n",
    "    def _encode_edge_features(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Encode edge features from transaction and account data.\n",
    "        \n",
    "        Returns:\n",
    "            Array of shape (n_edges, edge_features_dim)\n",
    "        \"\"\"\n",
    "        features_list = []\n",
    "        \n",
    "        # 1. Amount features (log transform to reduce skew)\n",
    "        amount_received = self.transactions['amount_received'].values.reshape(-1, 1)\n",
    "        amount_paid = self.transactions['amount_paid'].values.reshape(-1, 1)\n",
    "\n",
    "        log_amount_received = np.log10(amount_received)\n",
    "        log_amount_paid = np.log10(amount_paid)\n",
    "        \n",
    "        features_list.extend([log_amount_received, log_amount_paid])\n",
    "        \n",
    "        # 2. Amount ratio and difference\n",
    "        amount_ratio = (amount_received / (amount_paid + 1e-8)).reshape(-1, 1)\n",
    "        amount_diff = (amount_received - amount_paid).reshape(-1, 1)\n",
    "        \n",
    "        scaler_ratio = StandardScaler()\n",
    "        scaler_diff = StandardScaler()\n",
    "        \n",
    "        features_list.append(scaler_ratio.fit_transform(amount_ratio))\n",
    "        features_list.append(scaler_diff.fit_transform(amount_diff))\n",
    "        \n",
    "        # 3. Categorical features\n",
    "        one_hot_array = pd.get_dummies(self.transactions[['payment_format', 'receiving_currency', 'payment_currency']], dtype=float).to_numpy()\n",
    "        features_list.append(one_hot_array)\n",
    "        \n",
    "        # 4. Currency matching flags\n",
    "        currency_match = (\n",
    "            self.transactions['receiving_currency'] == self.transactions['payment_currency']\n",
    "        ).astype(float).values.reshape(-1, 1)\n",
    "        features_list.append(currency_match)\n",
    "        \n",
    "        # 5. Bank relationship features\n",
    "        same_bank = (\n",
    "            self.transactions['from_bank'] == self.transactions['to_bank']\n",
    "        ).astype(float).values.reshape(-1, 1)\n",
    "        features_list.append(same_bank)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        edge_features = np.hstack(features_list)\n",
    "        \n",
    "        print(f\"Edge features shape: {edge_features.shape}\")\n",
    "        return edge_features\n",
    "    \n",
    "    def _create_node_features(\n",
    "        self,\n",
    "        account_mapping: Dict[str, int]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Create node features from account metadata and transaction statistics.\n",
    "        \n",
    "        Args:\n",
    "            account_mapping: Mapping from account IDs to node indices\n",
    "            \n",
    "        Returns:\n",
    "            Array of shape (n_nodes, node_features_dim)\n",
    "        \"\"\"        \n",
    "        node_features_df = pd.DataFrame.from_dict(account_mapping, orient='index', columns=['node_id']).reset_index().rename(columns={'index': 'bank_account_id'})\n",
    "        \n",
    "        node_features_df = node_features_df.merge(\n",
    "            self.accounts,\n",
    "            on='bank_account_id',\n",
    "            how='left'\n",
    "        ).drop_duplicates()\n",
    "\n",
    "        # print('test: ', node_features_df)\n",
    "        node_features = pd.get_dummies(node_features_df[['entity_type']], dtype=float).to_numpy()\n",
    "\n",
    "        # Add degree centrality features (?)\n",
    "        print(f\"Node features shape: {node_features.shape}\")\n",
    "        return node_features\n",
    "    \n",
    "    def build_graph(\n",
    "        self,\n",
    "        train_ratio: float = 0.7,\n",
    "        val_ratio: float = 0.15,\n",
    "        test_ratio: float = 0.15,\n",
    "        seed: int = 42\n",
    "    ) -> GraphData:\n",
    "        \"\"\"\n",
    "        Build DGL heterogeneous graph for AML detection.\n",
    "        \n",
    "        Args:\n",
    "            train_ratio: Proportion of edges for training\n",
    "            val_ratio: Proportion of edges for validation\n",
    "            test_ratio: Proportion of edges for testing\n",
    "            seed: Random seed for reproducibility\n",
    "            \n",
    "        Returns:\n",
    "            AMLGraphData object containing graph and associated data\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Building DGL Graph for AML Detection\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. Create account mapping\n",
    "        account_mapping = self._create_account_mapping()\n",
    "        \n",
    "        # 2. Create edge list\n",
    "        src_nodes = [account_mapping[acc] for acc in self.transactions['from_bank_account_id']]\n",
    "        dst_nodes = [account_mapping[acc] for acc in self.transactions['to_bank_account_id']]\n",
    "\n",
    "        # 3. Create edge features\n",
    "        edge_features = self._encode_edge_features()\n",
    "        \n",
    "        # 4. Create node features\n",
    "        node_features = self._create_node_features(account_mapping)\n",
    "        \n",
    "        # 5. Build DGL graph\n",
    "        graph = dgl.graph((src_nodes, dst_nodes), num_nodes=len(account_mapping))\n",
    "        \n",
    "        # Add self-loops if requested\n",
    "        if self.add_self_loops:\n",
    "            graph = dgl.add_self_loop(graph)\n",
    "            print(f\"Added self-loops to graph\")\n",
    "        \n",
    "        # 6. Add features to graph\n",
    "        graph.ndata['feat'] = torch.FloatTensor(node_features)\n",
    "        graph.edata['feat'] = torch.FloatTensor(edge_features)\n",
    "\n",
    "        # 6a. Compute additional graph statistics\n",
    "        in_degrees = graph.in_degrees().float()\n",
    "        out_degrees = graph.out_degrees().float()\n",
    "        \n",
    "        # Add degree features to nodes\n",
    "        degree_features = torch.stack([in_degrees, out_degrees], dim=1)\n",
    "        graph.ndata['feat'] = torch.cat([graph.ndata['feat'], degree_features], dim=1)\n",
    "        \n",
    "        # 7. Add edge labels (laundering indicator)\n",
    "        edge_labels = torch.LongTensor(self.transactions['is_laundering'].values)\n",
    "        graph.edata['label'] = edge_labels\n",
    "        \n",
    "        # 8. Create train/val/test masks for edges\n",
    "        n_edges = graph.num_edges()\n",
    "        indices = np.random.permutation(n_edges)\n",
    "        \n",
    "        train_size = int(train_ratio * n_edges)\n",
    "        val_size = int(val_ratio * n_edges)\n",
    "        \n",
    "        train_idx = indices[:train_size]\n",
    "        val_idx = indices[train_size:train_size + val_size]\n",
    "        test_idx = indices[train_size + val_size:]\n",
    "        \n",
    "        train_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "        \n",
    "        train_mask[train_idx] = True\n",
    "        val_mask[val_idx] = True\n",
    "        test_mask[test_idx] = True\n",
    "        \n",
    "        graph.edata['train_mask'] = train_mask\n",
    "        graph.edata['val_mask'] = val_mask\n",
    "        graph.edata['test_mask'] = test_mask\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(\"Graph Statistics:\")\n",
    "        print(\"-\"*60)\n",
    "        print(f\"Nodes: {graph.num_nodes():,}\")\n",
    "        print(f\"Edges: {graph.num_edges():,}\")\n",
    "        print(f\"Node feature dim: {graph.ndata['feat'].shape[1]}\")\n",
    "        print(f\"Edge feature dim: {graph.edata['feat'].shape[1]}\")\n",
    "        print(f\"Average degree: {graph.num_edges() / graph.num_nodes():.2f}\")\n",
    "        print(f\"\\nTrain edges: {train_mask.sum().item():,} ({train_ratio*100:.1f}%)\")\n",
    "        print(f\"Val edges: {val_mask.sum().item():,} ({val_ratio*100:.1f}%)\")\n",
    "        print(f\"Test edges: {test_mask.sum().item():,} ({test_ratio*100:.1f}%)\")\n",
    "        print(f\"\\nLaundering edges: {edge_labels.sum().item():,} ({edge_labels.float().mean()*100:.3f}%)\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        return GraphData(\n",
    "            graph=graph,\n",
    "            labels=edge_labels,\n",
    "            train_mask=train_mask,\n",
    "            val_mask=val_mask,\n",
    "            test_mask=test_mask,\n",
    "            num_classes=2,\n",
    "            node_features_dim=graph.ndata['feat'].shape[1],\n",
    "            edge_features_dim=graph.edata['feat'].shape[1],\n",
    "            account_mapping=account_mapping\n",
    "        )\n",
    "    \n",
    "    def get_subgraph_sampler(\n",
    "        self,\n",
    "        graph_data: GraphData,\n",
    "        batch_size: int = 1024,\n",
    "        num_neighbors: List[int] = [10, 5],\n",
    "        mode: str = 'train'\n",
    "    ) -> dgl.dataloading.DataLoader:\n",
    "        \"\"\"\n",
    "        Create a neighborhood sampler for mini-batch training.\n",
    "        \n",
    "        Args:\n",
    "            graph_data: Processed graph data\n",
    "            batch_size: Number of edges per batch\n",
    "            num_neighbors: Number of neighbors to sample per layer\n",
    "            mode: One of 'train', 'val', or 'test'\n",
    "            \n",
    "        Returns:\n",
    "            DGL DataLoader for mini-batch training\n",
    "        \"\"\"\n",
    "        if mode == 'train':\n",
    "            mask = graph_data.train_mask\n",
    "        elif mode == 'val':\n",
    "            mask = graph_data.val_mask\n",
    "        else:\n",
    "            mask = graph_data.test_mask\n",
    "        \n",
    "        edge_ids = torch.where(mask)[0]\n",
    "        \n",
    "        sampler = dgl.dataloading.MultiLayerFullNeighborSampler(len(num_neighbors))\n",
    "        \n",
    "        # For edge classification, we need EdgeDataLoader\n",
    "        # Convert edge IDs to node pairs\n",
    "        # src, dst = graph_data.graph.find_edges(edge_ids)\n",
    "        edge_sampler = dgl.dataloading.as_edge_prediction_sampler(\n",
    "            sampler,\n",
    "            negative_sampler=None  # No negative sampling for supervised classification\n",
    "        )\n",
    "        \n",
    "        dataloader = dgl.dataloading.DataLoader(\n",
    "            graph_data.graph,\n",
    "            edge_ids,\n",
    "            edge_sampler,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=(mode == 'train'),\n",
    "            drop_last=False,\n",
    "            num_workers=2\n",
    "        )\n",
    "        \n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e9a2e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing AML Data Loader...\n",
      "Transactions: 100,000\n",
      "Accounts: 518,581\n",
      "\n",
      "============================================================\n",
      "Building DGL Graph for AML Detection\n",
      "============================================================\n",
      "Created account mapping: 81,352 unique accounts\n",
      "Edge features shape: (100000, 43)\n",
      "Node features shape: (81352, 6)\n",
      "\n",
      "------------------------------------------------------------\n",
      "Graph Statistics:\n",
      "------------------------------------------------------------\n",
      "Nodes: 81,352\n",
      "Edges: 100,000\n",
      "Node feature dim: 8\n",
      "Edge feature dim: 43\n",
      "Average degree: 1.23\n",
      "\n",
      "Train edges: 70,000 (70.0%)\n",
      "Val edges: 15,000 (15.0%)\n",
      "Test edges: 15,000 (15.0%)\n",
      "\n",
      "Laundering edges: 5 (0.005%)\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(trans_df.head(100000), accounts_df, add_self_loops=False)\n",
    "graph_data = loader.build_graph()\n",
    "subgraph_sampler = loader.get_subgraph_sampler(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9361fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernard/miniconda3/envs/cs5284_project/lib/python3.9/site-packages/dgl/dataloading/dataloader.py:1144: DGLWarning: Dataloader CPU affinity opt is not enabled, consider switching it on (see enable_cpu_affinity() or CPU best practices for DGL [https://docs.dgl.ai/tutorials/cpu/cpu_best_practises.html])\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([149601, 273850,  81204,  ...,   1921, 266964, 198585]), Graph(num_nodes=1402, num_edges=1024,\n",
      "      ndata_schemes={'feat': Scheme(shape=(8,), dtype=torch.float32), '_ID': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(43,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), '_ID': Scheme(shape=(), dtype=torch.int64)}), [Block(num_src_nodes=1970, num_dst_nodes=1823, num_edges=3478), Block(num_src_nodes=1823, num_dst_nodes=1402, num_edges=3060)])\n"
     ]
    }
   ],
   "source": [
    "for i in subgraph_sampler:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7179c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gat_model(\n",
    "    node_feat_dim: int,\n",
    "    edge_feat_dim: int,\n",
    "    hidden_dims: List[int] = [128, 64, 32],\n",
    "    num_heads: List[int] = [8, 8, 1],\n",
    "    **kwargs\n",
    ") -> GraphAttentionNetwork:\n",
    "    \"\"\"Create GAT model for AML detection.\"\"\"\n",
    "    return GraphAttentionNetwork(\n",
    "        in_node_feats=node_feat_dim,\n",
    "        in_edge_feats=edge_feat_dim,\n",
    "        hidden_dims=hidden_dims,\n",
    "        num_heads=num_heads,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c18d82fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernard/miniconda3/envs/cs5284_project/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Training GraphAttentionNetwork\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "DGLError",
     "evalue": "There are 0-in-degree nodes in the graph, output for those nodes will be invalid. This is harmful for some applications, causing silent performance regression. Adding self-loop on the input graph by calling `g = dgl.add_self_loop(g)` will resolve the issue. Setting ``allow_zero_in_degree`` to be `True` when constructing this module will suppress the check and let the code run.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m      9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m AMLModelTrainer(model, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nus/cs5284/AML-GNN-project/models.py:327\u001b[0m, in \u001b[0;36mAMLModelTrainer.train\u001b[0;34m(self, graph, num_epochs, early_stopping_patience, verbose)\u001b[0m\n\u001b[1;32m    324\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m train_loss, train_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[1;32m    330\u001b[0m val_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(graph, val_mask)\n",
      "File \u001b[0;32m~/nus/cs5284/AML-GNN-project/models.py:212\u001b[0m, in \u001b[0;36mAMLModelTrainer.train_epoch\u001b[0;34m(self, graph, mask)\u001b[0m\n\u001b[1;32m    209\u001b[0m graph \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Apply mask\u001b[39;00m\n\u001b[1;32m    219\u001b[0m logits_masked \u001b[38;5;241m=\u001b[39m logits[mask]\n",
      "File \u001b[0;32m~/miniconda3/envs/cs5284_project/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs5284_project/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/nus/cs5284/AML-GNN-project/models.py:127\u001b[0m, in \u001b[0;36mGraphAttentionNetwork.forward\u001b[0;34m(self, graph, node_features, edge_features)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Process through GAT layers\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (gat_layer, norm) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgat_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorms)):\n\u001b[0;32m--> 127\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mgat_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m h\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m h  \u001b[38;5;66;03m# Flatten multi-head outputs\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     h \u001b[38;5;241m=\u001b[39m norm(h)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs5284_project/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs5284_project/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs5284_project/lib/python3.9/site-packages/dgl/nn/pytorch/conv/gatconv.py:279\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[0;34m(self, graph, feat, edge_weight, get_attention)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_zero_in_degree:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (graph\u001b[38;5;241m.\u001b[39min_degrees() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 279\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\n\u001b[1;32m    280\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are 0-in-degree nodes in the graph, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput for those nodes will be invalid. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is harmful for some applications, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcausing silent performance regression. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdding self-loop on the input graph by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling `g = dgl.add_self_loop(g)` will resolve \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe issue. Setting ``allow_zero_in_degree`` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto be `True` when constructing this module will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuppress the check and let the code run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         )\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feat, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    292\u001b[0m     src_prefix_shape \u001b[38;5;241m=\u001b[39m feat[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mDGLError\u001b[0m: There are 0-in-degree nodes in the graph, output for those nodes will be invalid. This is harmful for some applications, causing silent performance regression. Adding self-loop on the input graph by calling `g = dgl.add_self_loop(g)` will resolve the issue. Setting ``allow_zero_in_degree`` to be `True` when constructing this module will suppress the check and let the code run."
     ]
    }
   ],
   "source": [
    "model = create_gat_model(\n",
    "        node_feat_dim=graph_data.node_features_dim,\n",
    "        edge_feat_dim=graph_data.edge_features_dim,\n",
    "        hidden_dims=[128, 64, 32],\n",
    "        num_heads=[8, 8, 1]\n",
    "    )\n",
    "    \n",
    "# Train\n",
    "trainer = AMLModelTrainer(model, learning_rate=0.001)\n",
    "history = trainer.train(graph_data.graph, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656bf30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5284_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
