{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cbe6d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc72823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernard/miniconda3/envs/cs5284_project/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import dgl\n",
    "# import dgl.graphbolt as gb\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "# from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from eda_src.data_loader import load_transactions, load_accounts, load_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2364f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HI-Small...\n",
      "\n",
      "\n",
      "Loading transactions from: /home/bernard/.cache/kagglehub/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml/versions/8/HI-Small_Trans.csv\n",
      "File size: 453.6 MB\n",
      "\n",
      "Loaded 5,078,345 transactions\n",
      "Date range: 2022-09-01 00:00:00 to 2022-09-18 16:18:00\n",
      "Laundering transactions: 5,177 (0.102%)\n",
      "\n",
      "Loading accounts from: /home/bernard/.cache/kagglehub/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml/versions/8/HI-Small_accounts.csv\n",
      "\n",
      "Loaded 518,581 accounts from 30470 banks\n",
      "\n",
      "Loading patterns from: /home/bernard/.cache/kagglehub/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml/versions/8/HI-Small_Patterns.txt\n",
      "\n",
      "Loaded patterns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>from_bank</th>\n",
       "      <th>from_account</th>\n",
       "      <th>to_bank</th>\n",
       "      <th>to_account</th>\n",
       "      <th>amount_received</th>\n",
       "      <th>receiving_currency</th>\n",
       "      <th>amount_paid</th>\n",
       "      <th>payment_currency</th>\n",
       "      <th>payment_format</th>\n",
       "      <th>is_laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-01 00:20:00</td>\n",
       "      <td>010</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>010</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id           timestamp from_bank from_account to_bank  \\\n",
       "0               0 2022-09-01 00:20:00       010    8000EBD30     010   \n",
       "\n",
       "  to_account  amount_received receiving_currency  amount_paid  \\\n",
       "0  8000EBD30          3697.34          US Dollar      3697.34   \n",
       "\n",
       "  payment_currency payment_format  is_laundering  \n",
       "0        US Dollar   Reinvestment              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank_name</th>\n",
       "      <th>bank_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>entity_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Portugal Bank #4507</td>\n",
       "      <td>331579</td>\n",
       "      <td>80B779D80</td>\n",
       "      <td>80062E240</td>\n",
       "      <td>Sole Proprietorship #50438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bank_name bank_id account_id  entity_id  \\\n",
       "0  Portugal Bank #4507  331579  80B779D80  80062E240   \n",
       "\n",
       "                  entity_name  \n",
       "0  Sole Proprietorship #50438  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern_id</th>\n",
       "      <th>pattern_type</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>from_bank</th>\n",
       "      <th>from_account</th>\n",
       "      <th>to_bank</th>\n",
       "      <th>to_account</th>\n",
       "      <th>amount_received</th>\n",
       "      <th>receiving_currency</th>\n",
       "      <th>amount_paid</th>\n",
       "      <th>payment_currency</th>\n",
       "      <th>payment_format</th>\n",
       "      <th>is_laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FAN-OUT</td>\n",
       "      <td>2022-09-01 00:06:00</td>\n",
       "      <td>021174</td>\n",
       "      <td>800737690</td>\n",
       "      <td>012</td>\n",
       "      <td>80011F990</td>\n",
       "      <td>2848.96</td>\n",
       "      <td>Euro</td>\n",
       "      <td>2848.96</td>\n",
       "      <td>Euro</td>\n",
       "      <td>ACH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pattern_id pattern_type           timestamp from_bank from_account to_bank  \\\n",
       "0           1      FAN-OUT 2022-09-01 00:06:00    021174    800737690     012   \n",
       "\n",
       "  to_account  amount_received receiving_currency  amount_paid  \\\n",
       "0  80011F990          2848.96               Euro      2848.96   \n",
       "\n",
       "  payment_currency payment_format  is_laundering  \n",
       "0             Euro            ACH              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = \"HI-Small\"\n",
    "\n",
    "print(f\"Loading {dataset_name}...\\n\")\n",
    "trans_df = load_transactions(dataset_size=dataset_name)\n",
    "accounts_df = load_accounts(dataset_size=dataset_name)\n",
    "patterns_df = load_patterns(dataset_size=dataset_name)\n",
    "\n",
    "display(trans_df.head(1))\n",
    "display(accounts_df.head(1))\n",
    "display(patterns_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca9b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional transformations - Transaction-level\n",
    "trans_df['timestamp'] = trans_df['timestamp'] - trans_df['timestamp'].min()\n",
    "# trans_df['from_account'] =  trans_df['from_account'].apply(lambda x: int(x,16))\n",
    "# trans_df['to_account'] =  trans_df['to_account'].apply(lambda x: int(x,16))\n",
    "trans_df['from_bank_account_id'] = trans_df['from_bank'] + '_' + trans_df['from_account']\n",
    "trans_df['to_bank_account_id'] = trans_df['to_bank'] + '_' + trans_df['to_account']\n",
    "\n",
    "# Additional transformations - Account-level\n",
    "accounts_df['bank_account_id'] = accounts_df['bank_id'] + '_' + accounts_df['account_id']\n",
    "accounts_df[['entity_type', 'entity_number']] = accounts_df['entity_name'].str.split(' #', expand=True)\n",
    "accounts_df = accounts_df[['bank_account_id','entity_type']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "113eb289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518581, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.get_dummies(accounts_df[['entity_type']], dtype=float).to_numpy()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22933725",
   "metadata": {},
   "source": [
    "### DGL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea6c0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GraphData:\n",
    "    \"\"\"Container for processed AML graph data ready for GNN training.\"\"\"\n",
    "    graph: dgl.DGLGraph\n",
    "    labels: torch.Tensor\n",
    "    train_mask: torch.Tensor\n",
    "    val_mask: torch.Tensor\n",
    "    test_mask: torch.Tensor\n",
    "    num_classes: int\n",
    "    node_features_dim: int\n",
    "    edge_features_dim: int\n",
    "    account_mapping: Dict[str, int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca3fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Data loader for Anti-Money Laundering graph construction with DGL.    \n",
    "    Supports GIN, PNA, and GAT models with temporal and edge features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        transactions_df: pd.DataFrame,\n",
    "        accounts_df: pd.DataFrame,\n",
    "        add_self_loops: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize AML data loader.\n",
    "        \n",
    "        Args:\n",
    "            transactions_df: Transaction data from load_transactions()\n",
    "            accounts_df: Account metadata from load_accounts()\n",
    "            add_self_loops: Whether to add self-loops to graph\n",
    "        \"\"\"\n",
    "        self.transactions = transactions_df.copy(deep=True)\n",
    "        self.accounts = accounts_df.copy(deep=True)\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        print(\"Initializing AML Data Loader...\")\n",
    "        print(f\"Transactions: {len(self.transactions):,}\")\n",
    "        print(f\"Accounts: {len(self.accounts):,}\")\n",
    "    \n",
    "    def _create_account_mapping(self) -> Dict[str, int]:\n",
    "        \"\"\"Create mapping from account IDs to node indices.\"\"\"\n",
    "        # Get unique accounts from both source and target\n",
    "        all_accounts = pd.concat([\n",
    "            self.transactions['from_bank_account_id'],\n",
    "            self.transactions['to_bank_account_id']\n",
    "        ]).unique()\n",
    "        \n",
    "        account_mapping = {acc: idx for idx, acc in enumerate(all_accounts)}\n",
    "        print(f\"Created account mapping: {len(account_mapping):,} unique accounts\")\n",
    "        return account_mapping\n",
    "    \n",
    "    def _encode_edge_features(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Encode edge features from transaction and account data.\n",
    "        \n",
    "        Returns:\n",
    "            Array of shape (n_edges, edge_features_dim)\n",
    "        \"\"\"\n",
    "        features_list = []\n",
    "        \n",
    "        # 1. Amount features (log transform to reduce skew)\n",
    "        amount_received = self.transactions['amount_received'].values.reshape(-1, 1)\n",
    "        amount_paid = self.transactions['amount_paid'].values.reshape(-1, 1)\n",
    "\n",
    "        log_amount_received = np.log10(amount_received)\n",
    "        log_amount_paid = np.log10(amount_paid)\n",
    "        \n",
    "        features_list.extend([log_amount_received, log_amount_paid])\n",
    "        \n",
    "        # 2. Amount ratio and difference\n",
    "        amount_ratio = (amount_received / (amount_paid + 1e-8)).reshape(-1, 1)\n",
    "        amount_diff = (amount_received - amount_paid).reshape(-1, 1)\n",
    "        \n",
    "        scaler_ratio = StandardScaler()\n",
    "        scaler_diff = StandardScaler()\n",
    "        \n",
    "        features_list.append(scaler_ratio.fit_transform(amount_ratio))\n",
    "        features_list.append(scaler_diff.fit_transform(amount_diff))\n",
    "        \n",
    "        # 3. Categorical features\n",
    "        one_hot_array = pd.get_dummies(self.transactions[['payment_format', 'receiving_currency', 'payment_currency']], dtype=float).to_numpy()\n",
    "        features_list.append(one_hot_array)\n",
    "        \n",
    "        # 4. Currency matching flags\n",
    "        currency_match = (\n",
    "            self.transactions['receiving_currency'] == self.transactions['payment_currency']\n",
    "        ).astype(float).values.reshape(-1, 1)\n",
    "        features_list.append(currency_match)\n",
    "        \n",
    "        # 5. Bank relationship features\n",
    "        same_bank = (\n",
    "            self.transactions['from_bank'] == self.transactions['to_bank']\n",
    "        ).astype(float).values.reshape(-1, 1)\n",
    "        features_list.append(same_bank)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        edge_features = np.hstack(features_list)\n",
    "        \n",
    "        print(f\"Edge features shape: {edge_features.shape}\")\n",
    "        return edge_features\n",
    "    \n",
    "    def _create_node_features(\n",
    "        self,\n",
    "        account_mapping: Dict[str, int]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Create node features from account metadata and transaction statistics.\n",
    "        \n",
    "        Args:\n",
    "            account_mapping: Mapping from account IDs to node indices\n",
    "            \n",
    "        Returns:\n",
    "            Array of shape (n_nodes, node_features_dim)\n",
    "        \"\"\"        \n",
    "        node_features_df = pd.DataFrame.from_dict(account_mapping, orient='index', columns=['node_id']).reset_index().rename(columns={'index': 'bank_account_id'})\n",
    "        \n",
    "        node_features_df = node_features_df.merge(\n",
    "            self.accounts,\n",
    "            on='bank_account_id',\n",
    "            how='left'\n",
    "        ).drop_duplicates()\n",
    "\n",
    "        node_features = pd.get_dummies(node_features_df[['entity_type']], dtype=float).to_numpy()\n",
    "\n",
    "        # Add degree centrality features (?)\n",
    "        print(f\"Node features shape: {node_features.shape}\")\n",
    "        return node_features\n",
    "    \n",
    "    def build_graph(\n",
    "        self,\n",
    "        train_ratio: float = 0.7,\n",
    "        val_ratio: float = 0.15,\n",
    "        test_ratio: float = 0.15,\n",
    "        seed: int = 42\n",
    "    ) -> GraphData:\n",
    "        \"\"\"\n",
    "        Build DGL heterogeneous graph for AML detection.\n",
    "        \n",
    "        Args:\n",
    "            train_ratio: Proportion of edges for training\n",
    "            val_ratio: Proportion of edges for validation\n",
    "            test_ratio: Proportion of edges for testing\n",
    "            seed: Random seed for reproducibility\n",
    "            \n",
    "        Returns:\n",
    "            AMLGraphData object containing graph and associated data\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Building DGL Graph for AML Detection\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. Create account mapping\n",
    "        account_mapping = self._create_account_mapping()\n",
    "        \n",
    "        # 2. Create edge list\n",
    "        src_nodes = [account_mapping[acc] for acc in self.transactions['from_bank_account_id']]\n",
    "        dst_nodes = [account_mapping[acc] for acc in self.transactions['to_bank_account_id']]\n",
    "\n",
    "        # 3. Create edge features\n",
    "        edge_features = self._encode_edge_features()\n",
    "        \n",
    "        # 4. Create node features\n",
    "        node_features = self._create_node_features(account_mapping)\n",
    "        \n",
    "        # 5. Build DGL graph\n",
    "        graph = dgl.graph((src_nodes, dst_nodes), num_nodes=len(account_mapping))\n",
    "        \n",
    "        # Add self-loops if requested\n",
    "        if self.add_self_loops:\n",
    "            graph = dgl.add_self_loop(graph)\n",
    "            print(f\"Added self-loops to graph\")\n",
    "        \n",
    "        # 6. Add features to graph\n",
    "        graph.ndata['feat'] = torch.FloatTensor(node_features)\n",
    "        graph.edata['feat'] = torch.FloatTensor(edge_features)\n",
    "\n",
    "        # 6a. Compute additional graph statistics\n",
    "        in_degrees = graph.in_degrees().float()\n",
    "        out_degrees = graph.out_degrees().float()\n",
    "        \n",
    "        # Add degree features to nodes\n",
    "        degree_features = torch.stack([in_degrees, out_degrees], dim=1)\n",
    "        graph.ndata['feat'] = torch.cat([graph.ndata['feat'], degree_features], dim=1)\n",
    "        \n",
    "        # 7. Add edge labels (laundering indicator)\n",
    "        edge_labels = torch.LongTensor(self.transactions['is_laundering'].values)\n",
    "        graph.edata['label'] = edge_labels\n",
    "        \n",
    "        # 8. Create train/val/test masks for edges\n",
    "        n_edges = graph.num_edges()\n",
    "        indices = np.random.permutation(n_edges)\n",
    "        \n",
    "        train_size = int(train_ratio * n_edges)\n",
    "        val_size = int(val_ratio * n_edges)\n",
    "        \n",
    "        train_idx = indices[:train_size]\n",
    "        val_idx = indices[train_size:train_size + val_size]\n",
    "        test_idx = indices[train_size + val_size:]\n",
    "        \n",
    "        train_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "        \n",
    "        train_mask[train_idx] = True\n",
    "        val_mask[val_idx] = True\n",
    "        test_mask[test_idx] = True\n",
    "        \n",
    "        graph.edata['train_mask'] = train_mask\n",
    "        graph.edata['val_mask'] = val_mask\n",
    "        graph.edata['test_mask'] = test_mask\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(\"Graph Statistics:\")\n",
    "        print(\"-\"*60)\n",
    "        print(f\"Nodes: {graph.num_nodes():,}\")\n",
    "        print(f\"Edges: {graph.num_edges():,}\")\n",
    "        print(f\"Node feature dim: {graph.ndata['feat'].shape[1]}\")\n",
    "        print(f\"Edge feature dim: {graph.edata['feat'].shape[1]}\")\n",
    "        print(f\"Average degree: {graph.num_edges() / graph.num_nodes():.2f}\")\n",
    "        print(f\"\\nTrain edges: {train_mask.sum().item():,} ({train_ratio*100:.1f}%)\")\n",
    "        print(f\"Val edges: {val_mask.sum().item():,} ({val_ratio*100:.1f}%)\")\n",
    "        print(f\"Test edges: {test_mask.sum().item():,} ({test_ratio*100:.1f}%)\")\n",
    "        print(f\"\\nLaundering edges: {edge_labels.sum().item():,} ({edge_labels.float().mean()*100:.3f}%)\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        return GraphData(\n",
    "            graph=graph,\n",
    "            labels=edge_labels,\n",
    "            train_mask=train_mask,\n",
    "            val_mask=val_mask,\n",
    "            test_mask=test_mask,\n",
    "            num_classes=2,\n",
    "            node_features_dim=graph.ndata['feat'].shape[1],\n",
    "            edge_features_dim=graph.edata['feat'].shape[1],\n",
    "            account_mapping=account_mapping\n",
    "        )\n",
    "    \n",
    "    def get_subgraph_sampler(\n",
    "        self,\n",
    "        graph_data: GraphData,\n",
    "        batch_size: int = 1024,\n",
    "        num_neighbors: List[int] = [10, 5],\n",
    "        mode: str = 'train'\n",
    "    ) -> dgl.dataloading.DataLoader:\n",
    "        \"\"\"\n",
    "        Create a neighborhood sampler for mini-batch training.\n",
    "        \n",
    "        Args:\n",
    "            graph_data: Processed graph data\n",
    "            batch_size: Number of edges per batch\n",
    "            num_neighbors: Number of neighbors to sample per layer\n",
    "            mode: One of 'train', 'val', or 'test'\n",
    "            \n",
    "        Returns:\n",
    "            DGL DataLoader for mini-batch training\n",
    "        \"\"\"\n",
    "        if mode == 'train':\n",
    "            mask = graph_data.train_mask\n",
    "        elif mode == 'val':\n",
    "            mask = graph_data.val_mask\n",
    "        else:\n",
    "            mask = graph_data.test_mask\n",
    "        \n",
    "        edge_ids = torch.where(mask)[0]\n",
    "        \n",
    "        sampler = dgl.dataloading.MultiLayerFullNeighborSampler(len(num_neighbors))\n",
    "        \n",
    "        # For edge classification, we need EdgeDataLoader\n",
    "        # Convert edge IDs to node pairs\n",
    "        # src, dst = graph_data.graph.find_edges(edge_ids)\n",
    "        edge_sampler = dgl.dataloading.as_edge_prediction_sampler(\n",
    "            sampler,\n",
    "            negative_sampler=None  # No negative sampling for supervised classification\n",
    "        )\n",
    "        \n",
    "        dataloader = dgl.dataloading.DataLoader(\n",
    "            graph_data.graph,\n",
    "            edge_ids,\n",
    "            edge_sampler,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=(mode == 'train'),\n",
    "            drop_last=False,\n",
    "            num_workers=2\n",
    "        )\n",
    "        \n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e9a2e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing AML Data Loader...\n",
      "Transactions: 5,078,345\n",
      "Accounts: 518,581\n",
      "\n",
      "============================================================\n",
      "Building DGL Graph for AML Detection\n",
      "============================================================\n",
      "Created account mapping: 515,088 unique accounts\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "loader = DataLoader(trans_df, accounts_df)\n",
    "graph_data = loader.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca4f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5284_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
